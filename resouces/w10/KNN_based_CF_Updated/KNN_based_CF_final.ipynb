{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0FI6PdE1YoN"
   },
   "source": [
    "# Import Necessary Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qwRX_2RCrWdg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJRU5o4d1iCC"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPlwg9AgrYgp",
    "outputId": "d2b853ad-f08f-40fa-e9a7-8dfa4c432469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 users\n",
      "1682 items\n"
     ]
    }
   ],
   "source": [
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('ml-100k/u.data', sep='\\t', names=names)\n",
    "df.head()\n",
    "\n",
    "i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    " 'Animation', 'Children\\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    " 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "items = pd.read_csv('ml-100k/u.item', sep='|', names=i_cols, encoding='latin-1')\n",
    "\n",
    "items.head()\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z90r54XGrmPj"
   },
   "source": [
    "# Split Dataset into Training Dataset and Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KlU-Lq16rlpN",
    "outputId": "652c555a-4e2e-478c-ebd5-bfb0dcb65eac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       user_id  item_id  rating  timestamp\n",
       " 99008       26      845       3  891377468\n",
       " 70589      929      474       4  879640126\n",
       " 25556      149      302       4  883512623\n",
       " 36710      521     1012       3  884476049\n",
       " 50935      588        1       4  890015684\n",
       " ...        ...      ...     ...        ...\n",
       " 83337      896       23       2  887159145\n",
       " 29364       56      117       5  892679439\n",
       " 59896      486      235       2  879875370\n",
       " 25564      215      313       5  891436543\n",
       " 2623       312      228       3  891699040\n",
       " \n",
       " [80000 rows x 4 columns],\n",
       "        user_id  item_id  rating  timestamp\n",
       " 56225      738      393       3  875350944\n",
       " 15046       82     1033       1  884714560\n",
       " 19915      350      193       4  882347653\n",
       " 42923      622      144       5  882592103\n",
       " 64125      758      185       4  881975182\n",
       " ...        ...      ...     ...        ...\n",
       " 76337      919      976       2  875289453\n",
       " 60386      774      650       1  888556893\n",
       " 92475      846      728       4  883949422\n",
       " 49627      478      134       2  889397467\n",
       " 58856      694      584       4  875727877\n",
       " \n",
       " [20000 rows x 4 columns])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gvaLspXUrg9L",
    "outputId": "fab9c6db-5d87-455a-a94f-ba8621f72d31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
       " 0     5.0   0.0   4.0   3.0   0.0   0.0   4.0   1.0   5.0   3.0  ...   0.0   \n",
       " 1     4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   2.0  ...   0.0   \n",
       " 2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 4     4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " ..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   5.0   0.0  ...   0.0   \n",
       " 939   0.0   0.0   0.0   2.0   0.0   0.0   4.0   5.0   0.0   0.0  ...   0.0   \n",
       " 940   0.0   0.0   0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0  ...   0.0   \n",
       " 941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 942   0.0   5.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   0.0   \n",
       " \n",
       "      1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
       " 0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " ..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       " 938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " \n",
       " [943 rows x 1682 columns],\n",
       "      0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
       " 0     0.0   3.0   0.0   0.0   3.0   5.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 4     0.0   3.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " ..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       " 938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0  ...   0.0   \n",
       " 940   5.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " 942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       " \n",
       "      1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
       " 0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " ..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       " 938   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 939   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 940   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 941   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " 942   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       " \n",
       " [943 rows x 1682 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Dataset\n",
    "train_ds = np.zeros((n_users, n_items))\n",
    "for row in train_df.itertuples():\n",
    "    train_ds[row[1]-1, row[2]-1] = row[3]\n",
    "train_ds = pd.DataFrame(train_ds)\n",
    "\n",
    "# Testing Dataset\n",
    "test_ds = np.zeros((n_users, n_items))\n",
    "for row in test_df.itertuples():\n",
    "    test_ds[row[1]-1, row[2]-1] = row[3]\n",
    "test_ds = pd.DataFrame(test_ds)\n",
    "\n",
    "train_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1ffZ6fCjYQ7"
   },
   "source": [
    "# Fitting the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYJZT1keazuc"
   },
   "source": [
    "## User-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bf9Ksc2OlL1"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient for Each Pair of Users in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH3O2sX3iBx1",
    "outputId": "7f163ae0-1a1c-4012-e856-c51666c5a7fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.66720241e-01,  1.25055723e-01, ...,\n",
       "         1.15748388e-01, -4.46245660e-02,  1.34284070e-01],\n",
       "       [ 1.66720241e-01,  1.00000000e+00, -4.81644589e-02, ...,\n",
       "        -9.21884805e-03,  7.18928274e-02,  1.57713334e-01],\n",
       "       [ 1.25055723e-01, -4.81644589e-02,  1.00000000e+00, ...,\n",
       "         7.80340302e-02, -4.17684899e-02,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.15748388e-01, -9.21884805e-03,  7.80340302e-02, ...,\n",
       "         5.00000000e-01, -4.71404520e-02,  1.77777785e-11],\n",
       "       [-4.46245660e-02,  7.18928274e-02, -4.17684899e-02, ...,\n",
       "        -4.71404520e-02,  1.00000000e+00,  2.47311836e-01],\n",
       "       [ 1.34284070e-01,  1.57713334e-01,  0.00000000e+00, ...,\n",
       "         1.77777785e-11,  2.47311836e-01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAMMA = 30\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_user_pearson_corr = np.zeros((n_users, n_users))\n",
    "\n",
    "for i, user_i_vec in enumerate(train_ds.values):\n",
    "    for j, user_j_vec in enumerate(train_ds.values):\n",
    "\n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        np_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "np_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OxHrFpIEHYm"
   },
   "source": [
    "### Predict Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z-REE2zqj5rt"
   },
   "outputs": [],
   "source": [
    "np_predictions = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 100\n",
    "EPSILON = 1e-9\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating > 0:\n",
    "        # find top-k most similar users as the current user, remove itself\n",
    "        sim_user_ids = np.argsort(np_user_pearson_corr[i])[-(K + 1):-1]\n",
    "\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = np_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(train_ds.values[i]) / (np.sum(np.clip(train_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "\n",
    "        # filter unrated items\n",
    "        #w = np.clip(sim_users[mask_rated_j, j], 0, 1)\n",
    "        #sim_r_sum_mean *= w\n",
    "        #print(sim_users[:, j])\n",
    "        \n",
    "        np_predictions[i][j] = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiPKuFjQudyM"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQZSW98ZGDJR"
   },
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20UzmEf9uhF_",
    "outputId": "94c5c749-6a8c-449c-ba64-eff5427ffcd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on Tesing set (User-based): 0.7449956634851203\n"
     ]
    }
   ],
   "source": [
    "#==================MAE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# absolute error on all ratings\n",
    "absolute_error = np.abs(np_predictions - labels)\n",
    "\n",
    "# weight\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# absoulte error on rated ratings\n",
    "abs_error = absolute_error * weight\n",
    "\n",
    "# MAE\n",
    "MAE = np.sum(abs_error) / np.sum(weight)\n",
    "\n",
    "print(\"MAE on Tesing set (User-based): \" + str(MAE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_L7yqJ4HXJa"
   },
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mV-BhWhQvtAV",
    "outputId": "dd88af28-6ae9-49e6-fe5c-9077cc345470"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Tesing set (User-based): 0.9582882848302513\n"
     ]
    }
   ],
   "source": [
    "#==================RMSE on Testing set===================\n",
    "labels = test_ds.values\n",
    "\n",
    "# squared error on all ratings\n",
    "squared_error = np.square(np_predictions - labels)\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# squared error on rated ratings\n",
    "squared_error = squared_error * weight\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(squared_error) / np.sum(weight))\n",
    "\n",
    "print(\"RMSE on Tesing set (User-based): \" + str(RMSE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecoieIQTbQZV"
   },
   "source": [
    "## Item-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XHtJ0LpbQZW"
   },
   "source": [
    "### Compute Pearson Correlation Coefficient for Each Pair of Users in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgPMV2sobQZW",
    "outputId": "97f5fec9-ce61-4df0-c7c4-050485aa78d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  2.41902008e-01,  2.55683792e-01, ...,\n",
       "         0.00000000e+00,  1.15163155e-02,  0.00000000e+00],\n",
       "       [ 2.41902008e-01,  1.00000000e+00,  3.08734284e-01, ...,\n",
       "         0.00000000e+00, -1.90769239e-02, -1.90769239e-02],\n",
       "       [ 2.55683792e-01,  3.08734284e-01,  1.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.60000012e-03],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         1.60000026e-10,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.15163155e-02, -1.90769239e-02,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  3.60000056e-10,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -1.90769239e-02, -1.60000012e-03, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  3.60000056e-10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DELTA = 25\n",
    "EPSILON = 1e-9\n",
    "\n",
    "np_item_pearson_corr = np.zeros((n_items, n_items))\n",
    "\n",
    "for i, item_i_vec in enumerate(train_ds.T.values):\n",
    "    for j, item_j_vec in enumerate(train_ds.T.values):\n",
    "\n",
    "        # ratings corated by the current pair od items\n",
    "        mask_i = item_i_vec > 0\n",
    "        mask_j = item_j_vec > 0\n",
    "\n",
    "        # corrated index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of item_i_vec and item_j_vec\n",
    "        mean_item_i = np.sum(item_i_vec) / (np.sum(np.clip(item_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_item_j = np.sum(item_j_vec) / (np.sum(np.clip(item_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        item_i_sub_mean = item_i_vec[corrated_index] - mean_item_i\n",
    "        item_j_sub_mean = item_j_vec[corrated_index] - mean_item_j\n",
    "\n",
    "        r_ui_sub_ri_sq = np.square(item_i_sub_mean)\n",
    "        r_uj_sub_rj_sq = np.square(item_j_sub_mean)\n",
    "\n",
    "        r_ui_sub_ri_sq_sum_sqrt = np.sqrt(np.sum(r_ui_sub_ri_sq))\n",
    "        r_uj_sub_rj_sq_sum_sqrt = np.sqrt(np.sum(r_uj_sub_rj_sq))\n",
    "\n",
    "        sim = np.sum(item_i_sub_mean * item_j_sub_mean) / (r_ui_sub_ri_sq_sum_sqrt * r_uj_sub_rj_sq_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), DELTA) / DELTA) * sim\n",
    "\n",
    "        np_item_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "np_item_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EANmxRhbQZX"
   },
   "source": [
    "### Predict Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vyysZ6e7bQZX"
   },
   "outputs": [],
   "source": [
    "np_predictions = np.zeros((n_users, n_items))\n",
    "\n",
    "K = 10\n",
    "EPSILON = 1e-9\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "    if rating > 0:\n",
    "        # find top-k most similar items as the current item, remove itself\n",
    "        sim_item_ids = np.argsort(np_item_pearson_corr[j])[-(K + 1):-1]\n",
    "\n",
    "        # the coefficient values of similar items\n",
    "        sim_val = np_item_pearson_corr[j][sim_item_ids]\n",
    "\n",
    "        # the average value of the current item's ratings\n",
    "        sim_items = train_ds.T.values[sim_item_ids]\n",
    "        item_mean = np.sum(train_ds.T.values[j]) / (np.sum(np.clip(train_ds.T.values[j], 0, 1)) + EPSILON)\n",
    "        sim_item_mean = np.sum(sim_items, axis=1) / (np.sum(np.clip(sim_items, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # sim(u, v) * (r_v - mean_v)\n",
    "        sim_r_sum_mean = sim_val * (sim_items[:, i] - sim_item_mean) \n",
    "\n",
    "        # filter unrated items\n",
    "        w = np.clip(sim_items[:, i], 0, 1)\n",
    "        sim_r_sum_mean *= w\n",
    "\n",
    "        np_predictions[i][j] = item_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val * w) + EPSILON)    \n",
    "        np_predictions[i][j] = np.clip(np_predictions[i][j], 0, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rIh6rpJbQZY"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbMQzZlibQZY"
   },
   "source": [
    "#### Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bg2OzOBXbQZZ",
    "outputId": "8e032639-a4ca-4d72-8194-7c2a36611e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on Tesing set (Item-based): 0.8086991868302481\n"
     ]
    }
   ],
   "source": [
    "#==================MAE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# absolute error on all ratings\n",
    "absolute_error = np.abs(np_predictions - labels)\n",
    "\n",
    "# weight\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# absoulte error on rated ratings\n",
    "abs_error = absolute_error * weight\n",
    "\n",
    "# MAE\n",
    "MAE = np.sum(abs_error) / np.sum(weight)\n",
    "\n",
    "print(\"MAE on Tesing set (Item-based): \" + str(MAE));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ze_3YW5GbQZZ"
   },
   "source": [
    "#### Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FEh_WNPXbQZa",
    "outputId": "3be0306d-72e2-4a82-fc84-06f00b746193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Tesing set (Item-based): 1.0500551669579288\n"
     ]
    }
   ],
   "source": [
    "#==================RMSE on Testing set===================#\n",
    "labels = test_ds.values\n",
    "\n",
    "# squared error on all ratings\n",
    "squared_error = np.square(np_predictions - labels)\n",
    "weight = np.clip(labels, 0, 1)\n",
    "\n",
    "# squared error on rated ratings\n",
    "squared_error = squared_error * weight\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(squared_error) / np.sum(weight))\n",
    "\n",
    "print(\"RMSE on Tesing set (Item-based): \" + str(RMSE));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6be1nHnBRSl9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KNN_based_CF_final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
